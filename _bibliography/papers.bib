---
---
@misc{gupte2024revisiting,
      abbr={arXiv},
      title={Revisiting Active Learning in the Era of Vision Foundation Models}, 
      author={Sanket Rajan Gupte* and Josiah Aklilu* and Jeffrey J. Nirschl and Serena Yeung-Levy},
      year={2024},
      abstract={Foundation vision or vision-language models are trained on large unlabeled or noisy data and learn robust representations that can achieve impressive zero- or few-shot performance on diverse tasks. Given these properties, they are a natural fit for active learning (AL), which aims to maximize labeling efficiency, but the full potential of foundation models has not been explored in the context of AL, specifically in the low-budget regime. In this work, we evaluate how foundation models influence three critical components of effective AL, namely, 1) initial labeled pool selection, 2) ensuring diverse sampling, and 3) the trade-off between representative and uncertainty sampling. We systematically study how the robust representations of foundation models (DINOv2, OpenCLIP) challenge existing findings in active learning. Our observations inform the principled construction of a new simple and elegant AL strategy that balances uncertainty estimated via dropout with sample diversity. We extensively test our strategy on many challenging image classification benchmarks, including natural images as well as out-of-domain biomedical images that are relatively understudied in the AL literature. Source code will be made available.},
      eprint={2401.14555},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      selected={true}
}

@article{doi:10.1056/AIoa2300088,
  abbr={NEJM AI},
  author = {Josiah G. Aklilu  and Min Woo Sun  and Shelly Goel  and Sebastiano Bartoletti  and Anita Rau  and Griffin Olsen  and Kay S. Hung  and Sophie L. Mintz  and Vicki Luong  and Arnold Milstein  and Mark J. Ott  and Robert Tibshirani  and Jeffrey K. Jopling  and Eric C. Sorenson  and Dan E. Azagury  and Serena Yeung-Levy },
  title = {Artificial Intelligence Identifies Factors Associated with Blood Loss and Surgical Experience in Cholecystectomy},
  journal = {NEJM AI},
  volume = {1},
  number = {2},
  pages = {AIoa2300088},
  year = {2024},
  doi = {10.1056/AIoa2300088},
  URL = {https://ai.nejm.org/doi/abs/10.1056/AIoa2300088},
  eprint = {https://ai.nejm.org/doi/pdf/10.1056/AIoa2300088},
  abstract = { A computer vision model developed to recognize fine-grained surgical activity in laparoscopic cholecystectomy videos reveals associations among surgical behaviors, adverse outcomes, and surgical skills. },
  selected={true}
}

@InProceedings{pmlr-v182-aklilu22a,
  abbr={MLHC},
  title={ALGES: Active Learning with Gradient Embeddings for Semantic Segmentation of Laparoscopic Surgical Images},
  author={Aklilu, Josiah and Yeung, Serena},
  booktitle={Proceedings of the 7th Machine Learning for Healthcare Conference},
  pages={892--911},
  year={2022},
  editor={Lipton, Zachary and Ranganath, Rajesh and Sendak, Mark and Sjoding, Michael and Yeung, Serena},
  volume={182},
  series={Proceedings of Machine Learning Research},
  month={Aug},
  publisher={PMLR},
  pdf={https://proceedings.mlr.press/v182/aklilu22a/aklilu22a.pdf},
  url={https://proceedings.mlr.press/v182/aklilu22a.html},
  abstract={Annotating medical images for the purposes of training computer vision models is an extremely laborious task that takes time and resources away from expert clinicians. Active learning (AL) is a machine learning paradigm that mitigates this problem by deliberately proposing data points that should be labeled in order to maximize model performance. We propose a novel AL algorithm for segmentation, ALGES, that utilizes gradient embeddings to effectively select laparoscopic images to be labeled by some external oracle while reducing annotation effort. Given any unlabeled image, our algorithm treats predicted segmentations as truth and computes gradients with respect to the model parameters of the last layer in a segmentation network. The norms of these per-pixel gradient vectors correspond to the magnitude of the induced change in model parameters and contain rich information about the modelâ€™s predictive uncertainty. Our algorithm then computes gradients embeddings in two ways, and we employ a center-finding algorithm with these embeddings to procure representative and diverse batches in each round of AL. An advantage of our approach is extensibility to any model architecture and differentiable loss scheme for semantic segmentation. We apply our approach to a public data set of laparoscopic cholecystectomy images and show that it outperforms current AL algorithms in selecting the most informative data points for improving the segmentation model. Our code is available at https://github.com/josaklil-ai/surg-active-learning.},
  code={https://github.com/josaklil-ai/surg-active-learning},
  selected={true}
}